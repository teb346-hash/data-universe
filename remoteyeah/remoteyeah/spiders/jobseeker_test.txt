import re
import scrapy


class JobseekerSpider(scrapy.Spider):
    name = "jobseeker"
    allowed_domains = ["remoteyeah.com"]
    start_urls = ["https://remoteyeah.com/"]

    def parse(self, response):
        html = response.text   
        
        def pre_process(txt):            
            t = re.sub(r"<[^>]+>", " ", txt)          
            t = t.replace("\xa0", " ").replace("&nbsp;", " ")
            t = re.sub(r"\s+", " ", t).strip()     
            return t
        
        html = pre_process(html)
        
        def pick(pattern: str):
            m = re.search(pattern, html, flags=re.I)
            if not m:
                return None
            return int(m.group(1).replace(",", "").replace(".", ""))

        jobs_posted = pick(r"([0-9][0-9,\.]*)\s+jobs\s+posted")
        jobs_found = pick(r"([0-9][0-9,\.]*)\s+jobs\s+found\.?")

        yield {
            "url": response.url,
            "jobs_posted": jobs_posted, 
            "jobs_found": jobs_found,    
        }
